# K-Nearest-Neighbor-Classification-Project
A machine learning project that illustrates the use of the K-Nearest Neighbors algorithm from scratch. Here, multiple distance metrics were compared, decision boundaries were visualized, model performance was evaluated using confusion matrices and classification reports, and the best value of k for the highest accuracy was identified
![Introduction]()
The K-Nearest Neighbors (KNN) algorithm is a simple yet powerful supervised machine learning technique used for both classification and regression problems. In this project, we focus on classification. The algorithm works by storing all the available data points and classifying new data points based on a similarity measureâ€”most commonly distance functions. When a new example is introduced, KNN finds the K nearest data points from the training set and assigns the most common label among them as the predicted class.
<p align="center">
  <img src="0_ItVKiyx2F3ZU8zV5.png" width="500"/>
</p>
The figure below illustrate the yellow square represents a new sample that needs to be classified, and the nearby red stars and green triangles represent two different classes. The class of the new point is determined based on the majority of its nearest neighbors.

